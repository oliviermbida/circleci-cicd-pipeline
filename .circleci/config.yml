version: 2.1
orbs: 
  jira: circleci/jira@1.3.1
  slack: circleci/slack@4.10.1

# parameters:
#   run_integration_tests:
#     type: boolean
#     default: false

commands:
#   destroy-environment:
#     description: Destroy back-end and front-end cloudformation stacks given a workflow ID.
#     parameters:
#       # Add parameter here   
#     steps:
#       - run:
#           name: Destroy environments
#           when: on_fail
#           command: |
#             # Your code here
#             exit 1

#   revert-migrations:
#     description: Revert the last migration if successfully run in the current workflow.
#     parameters:
#       # Add parameter here     
#     steps:
#       - run:
#           name: Revert migrations
#           # Add when this will run
#           command: |
#             # Curl command here to see if there was a successful migration associated with the workflow id, store result in SUCCESS variable
#             SUCCESS = 1
#             if(( $SUCCESS==1 )); 
#             then
#             #  cd ~/project/backend
#             #  npm install
#             #  Add revert code here. You can find this in the Getting Started section.
#               exit 1
#             fi
  check_master:
    description: Stop job if not master branch but continue with other jobs in pipeline          
    steps:        
      - run: 
          name: Check if master 
          command: |
            # If condition is true stop this job but continue with others jobs in the pipeline
            if [ "$CIRCLE_BRANCH" != "master" ]; then
                circleci-agent step halt
            fi
  commit_to_github:
    description: Commit to github
    parameters:
      commit_message:
        type: string
        default: "NO_BUILD Auto commit from CircleCI [skip ci]"
    steps: 
      # - checkout
      # For a self-hosted runner, ensure that you have an ssh-agent on your system 
      # to successfully use the add_ssh_keys step. 
      # The SSH key is written to $HOME/.ssh/id_rsa_<fingerprint>, 
      # where $HOME is the home directory of the user configured to execute jobs, 
      # and <fingerprint> is the fingerprint of the key. 
      # A host entry is also appended to $HOME/.ssh/config, 
      # along with a relevant IdentityFile option to use the key.
      - add_ssh_keys:
          fingerprints:
            - "<copy-paste-fingerprint-here>"
      - run:
          name: Commit to GitHub
          command: |
            if [[ "${CIRCLE_USERNAME}" = $USER_NAME && -z "${CIRCLE_PULL_REQUEST}" ]]
            then
              printf "%s" 'github.com ssh-rsa <copy-paste-fingerprint-here>
              ' >> "$HOME/.ssh/known_hosts"

              export GIT_SSH_COMMAND='ssh -i "$HOME/.ssh/id_rsa" -o UserKnownHostsFile="$HOME/.ssh/known_hosts"'
              echo "Committing to GitHub"

              # use git+ssh instead of https
              git config --global url."ssh://git@github.com".insteadOf "https://github.com" || true
              git config --global gc.auto 0 || true
              git config user.email $USER_EMAIL
              git config user.name $USER_NAME
              git checkout master
              git commit --allow-empty -am <<parameters.commit_message>>
              git push origin master
            else
              echo "No commit to GitHub"
            fi
  revert-commit:
    description: To revert a commit on fail , it needs to have a REVERT trigger in commit message
    parameters:
      commit_sha:
        type: string
    steps: 
      # - checkout
      # - add_ssh_keys:
      #     fingerprints:
      #       - "<copy-paste-fingerprint-here>"

      # SSH_CONFIG_DIR='/home/circleci/.ssh'
      - run: 
          name: Revert last commit on fail
          command: |
            commit_message=$(git log -1 HEAD --pretty=format:%s)
            if [[ $commit_message == *REVERT* ]]; then
            echo "Revert commit on Fail"

            echo "Using SSH Config Dir '$SSH_CONFIG_DIR'"
            git --version 

            mkdir -p "$SSH_CONFIG_DIR"
            chmod 0700 "$SSH_CONFIG_DIR"

            printf "%s" 'github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ==
            github.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEmKSENjQEezOmxkZMy7opKgwFB9nkt5YRrYMjNuG5N87uRgg6CLrbo5wAdT/y6v0mKV0U2w0WZ2YB/++Tpockg=
            github.com ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIOMqqnkVzrm0SdG6UOoqKLsabgH5C9okWi0dh2l9GKJl
            bitbucket.org ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAubiN81eDcafrgMeLzaFPsw2kNvEcqTKl/VqLat/MaB33pZy0y3rJZtnqwR2qOOvbwKZYKiEO1O6VqNEBxKvJJelCq0dTXWT5pbO2gDXC6h6QDXCaHo6pOHGPUy+YBaGQRGuSusMEASYiWunYN0vCAI8QaXnWMXNMdFP3jHAJH0eDsoiGnLPBlBp4TNm6rYI74nMzgz3B9IikW4WVK+dc8KZJZWYjAuORU3jc1c/NPskD2ASinf8v3xnfXeukU0sJ5N6m5E8VLjObPEO+mN2t/FZTMZLiFqPWc/ALSqnMnnhwrNi2rbfg/rd/IpL8Le3pSBne8+seeFVBoGqzHM9yXw==
            gitlab.com ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBFSMqzJeV9rUzU4kWitGjeR4PWSa29SPqJ1fVkhtj3Hw9xjLVXVYrU9QlYWrOLXBpQ6KWjbjTDTdDkoohFzgbEY=
            ' >> "$SSH_CONFIG_DIR/known_hosts"
            chmod 0600 "$SSH_CONFIG_DIR/known_hosts"

            rm -f "$SSH_CONFIG_DIR/id_rsa"
            printf "%s" "$CHECKOUT_KEY" > "$SSH_CONFIG_DIR/id_rsa"
            chmod 0600 "$SSH_CONFIG_DIR/id_rsa"
            if (: "${CHECKOUT_KEY_PUBLIC?}") 2>/dev/null; then
              rm -f "$SSH_CONFIG_DIR/id_rsa.pub"
              printf "%s" "$CHECKOUT_KEY_PUBLIC" > "$SSH_CONFIG_DIR/id_rsa.pub"
            fi

            export GIT_SSH_COMMAND='ssh -i "$SSH_CONFIG_DIR/id_rsa" -o UserKnownHostsFile="$SSH_CONFIG_DIR/known_hosts"'

            # use git+ssh instead of https
            git config --global url."ssh://git@github.com".insteadOf "https://github.com" || true
            git config --global gc.auto 0 || true
            git config --global user.email $USER_EMAIL
            git config --global user.name $USER_NAME

            # Caution using reset: this may cause push issues as the reverted commit will not exist
            #git reset --hard <<parameters.commit_sha>> 
            #git push --force

            # This reverses last commit but does not delete that commit history
            git revert --no-commit <<parameters.commit_sha>> 
            git push --force
      
            #curl --request POST \
            #  --url https://circleci.com/api/v2/workflow/$CIRCLE_WORKFLOW_ID/cancel \
            #  --header "Circle-Token: ${CIRCLE_TOKEN}"
            fi           
# Similar to [skip ci] or [ci skip] in commit message
  cancel-workflow:
    description: Cancel workflow given a commit message to stop it being run automatically
    parameters:
      workflow_id:
        type: string
        default: $CIRCLE_WORKFLOW_ID
      custom-identifier:
        type: string
        default: "NO_BUILD"
    steps: 
      - checkout
      # - run: git submodule sync
      # - run: git submodule update --init
      - run:
          name: Stop automatic builds 
          command: |
            commit_message=$(git log -1 HEAD --pretty=format:%s)
            if [[ $commit_message == *<<parameters.custom-identifier>>* ]]; then
            echo "<<parameters.custom-identifier>> commit, cancelling workflow <<parameters.workflow_id>>"
            curl --request POST \
              --url https://circleci.com/api/v2/workflow/<<parameters.workflow_id>>/cancel \
              --header "Circle-Token: ${CIRCLE_TOKEN}"
            fi
  scan:
    description: >
      Detect bugs and vulnerabilities using sonar scanner
      Requires a sonarcloud account where report is posted
      with the same projectKey
    parameters:
      cache_version:
        default: 1
        description: increment this value if the cache is corrupted and you want to start with a clean cache
        type: integer
      project_root:
        default: .
        description: the root of the project that should be analyzed (relative to the root directory of the repository)
        type: string
      exclusions:
        type: string
        default: "**/*.yaml,**/*.yml"
      host_url:
        type: string
        default: $SONARQUBE_SERVER_URL
      sources:
        type: string
        default: "."
      runner_opts:
        type: string
        default: "-Xms1024m"
      projectKey:
        type: string
        default: "circle-cicd-pipeline"
      organization:
        type: string
        default: $SONARQUBE_SERVER_ORG
    steps:
      - run:
          command: mkdir -p /tmp/cache/scanner
          name: Create cache directory if it doesn't exist
      - restore_cache:
          keys:
            - v<<parameters.cache_version>>-sonarcloud-scanner-4.7.0.2747
      - run:
          name: SonarCloud
          command: |
            set -e
            VERSION=4.7.0.2747
            SCANNER_DIRECTORY=/tmp/cache/scanner
            export SONAR_USER_HOME=$SCANNER_DIRECTORY/.sonar
            OS="linux"
            echo $SONAR_USER_HOME

            export SONAR_RUNNER_OPTS="<< parameters.runner_opts >>"

            if [[ ! -x "$SCANNER_DIRECTORY/sonar-scanner-$VERSION-$OS/bin/sonar-scanner" ]]; then
              curl -Ol https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-$VERSION-$OS.zip
              unzip -qq -o sonar-scanner-cli-$VERSION-$OS.zip -d $SCANNER_DIRECTORY
            fi

            chmod +x $SCANNER_DIRECTORY/sonar-scanner-$VERSION-$OS/bin/sonar-scanner
            chmod +x $SCANNER_DIRECTORY/sonar-scanner-$VERSION-$OS/jre/bin/java

            cd <<parameters.project_root>>
            $SCANNER_DIRECTORY/sonar-scanner-$VERSION-$OS/bin/sonar-scanner \
            -Dsonar.organization=<< parameters.organization >> \
            -Dsonar.projectKey=<< parameters.projectKey >> \
            -Dsonar.host.url=<< parameters.host_url >> \
            -Dsonar.login=$SONAR_TOKEN \
            -Dsonar.projectBaseDir=<< parameters.project_root >> \
            -Dsonar.sources=<< parameters.sources >> \
            -Dsonar.exclusions="<< parameters.exclusions >>"                  
      - save_cache:
          key: v<<parameters.cache_version>>-sonarcloud-scanner-4.7.0.2747
          paths: /tmp/cache/scanner

# AWS CLI v2           
# Could use the Orb circleci/aws-cli@3.1.1
# Best to know which commands are executed if you are security aware
# You also reduce the overheads of a generic Orb
  install_aws:
    description: Install the AWS CLI via Pip if not already installed.
    parameters:
      binary-dir:
        default: /usr/local/bin
        description: >
          The main aws program in the install directory is symbolically linked to
          the file aws in the specified path. Defaults to /usr/local/bin
        type: string
      install-dir:
        default: /usr/local/aws-cli
        description: >
          Specify the installation directory of AWS CLI. Defaults to
          /usr/local/aws-cli
        type: string
    steps:
      - run:
          command: |
            curl -sSL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64$1.zip" -o "awscliv2.zip"
            unzip -q -o awscliv2.zip
            sudo ./aws/install -i "${PARAM_AWS_CLI_INSTALL_DIR}" -b "${PARAM_AWS_CLI_BINARY_DIR}"
            rm -r awscliv2.zip ./aws

            aws --version
          environment:
            PARAM_AWS_CLI_BINARY_DIR: <<parameters.binary-dir>>
            PARAM_AWS_CLI_INSTALL_DIR: <<parameters.install-dir>>
          name: Install AWS CLI v2
  # configure_aws:
  #   description: Setup AWS CLI v2.
  #   parameters:
  #     access_key_id: 
  #       type: string
  #       description: AWS access key Id
  #       default: $AWS_USER_ACCESS_KEY_ID
  #     secret_access_key: 
  #       type: string
  #       description: AWS secret access key
  #       default: $AWS_USER_SECRET_ACCESS_KEY
  #     profile_name: 
  #       type: string
  #       description: AWS CLI profile name
  #       default: $AWS_CLI_PROFILE_NAME
  #     region: 
  #       type: string
  #       description: AWS default region
  #       default: $AWS_DEFAULT_REGION
  #   steps:
  #     - run:
  #         name: Configure AWS Access Key ID
  #         command: |
  #           # AWS CLI supported environment variables
  #           AWS_ACCESS_KEY_ID=$(eval echo "$PARAM_AWS_CLI_ACCESS_KEY_ID")

  #           AWS_SECRET_ACCESS_KEY=$(eval echo "$PARAM_AWS_CLI_SECRET_ACCESS_KEY")

  #           AWS_DEFAULT_REGION=$(eval echo "$PARAM_AWS_CLI_REGION")

  #           aws configure set aws_access_key_id \
  #               "$PARAM_AWS_CLI_ACCESS_KEY_ID" \
  #               --profile "$PARAM_AWS_CLI_PROFILE_NAME"

  #           aws configure set aws_secret_access_key \
  #               "$PARAM_AWS_CLI_SECRET_ACCESS_KEY" \
  #               --profile "$PARAM_AWS_CLI_PROFILE_NAME"

  #           aws configure set default.region "$PARAM_AWS_CLI_REGION" \
  #               --profile "$PARAM_AWS_CLI_PROFILE_NAME"
                
  #         environment:
  #           PARAM_AWS_CLI_ACCESS_KEY_ID: <<parameters.access_key_id>>
  #           PARAM_AWS_CLI_PROFILE_NAME: <<parameters.profile_name>>
  #           PARAM_AWS_CLI_REGION: <<parameters.region>>
  #           PARAM_AWS_CLI_SECRET_ACCESS_KEY: <<parameters.secret_access_key>>
  #     - persist_to_workspace:
  #         root: ~/.aws
  #         paths:
  #           - credentials*
  #           - config*
  # stack_status:
  #   description: Check status of stack updates
  #   parameters: 
  #     # user_role:
  #     #   description: IAM user role
  #     #   type: string
  #     #   default: $AWS_CLI_PROFILE_NAME
  #     stackname:
  #       description: Name of stack 
  #       type: string
  #   steps:
  #     - run:
  #         name: Stack Status 
  #         command: |
  #           while [ 1 ]   # Endless loop.
  #           do
  #               stack_Status=$(aws --profile <<parameters.user_role>> --output text --query "Stacks[0].StackStatus" cloudformation describe-stacks \
  #                   --stack-name <<parameters.stackname>>)
  #               echo "Stack Status: $stack_Status"
  #               if [[ $stack_Status == "CREATE_COMPLETE" || $stack_Status == "UPDATE_COMPLETE"  ]]; then
  #                   echo "Exiting stack status: $stack_Status"
  #                   exit 0
  #               elif [[ $stack_Status == "CREATE_FAILED" || $stack_Status == "ROLLBACK_IN_PROGRESS" || $stack_Status == "ROLLBACK_COMPLETE" || $stack_Status == "UPDATE_ROLLBACK_COMPLETE" || $stack_Status == "DELETE_IN_PROGRESS" ]]; then
  #                   echo "Exiting stack status: $stack_Status"
  #                   exit 1
  #               fi
  #               sleep 5
  #           done
  # change_status:
  #   description: Wait for changes status CREATE_COMPLETE. 
  #   parameters:
  #     # user_role:
  #     #   description: IAM user role
  #     #   type: string
  #     #   default: $AWS_CLI_PROFILE_NAME 
  #     changename:
  #       description: Name of stack change set
  #       type: string
  #   steps:
  #     - run:
  #         name: Change-set Status 
  #         command: |
  #           while [ 1 ]   # Endless loop.
  #           do
  #               change_Status=$(aws --profile <<parameters.user_role>> --output text --query "Status" cloudformation describe-change-set \
  #                   --change-set-name <<parameters.changename>> --stack-name $CFN_STACKS)
  #               echo "Change Status: $change_Status"
  #               if [[ $change_Status == "CREATE_COMPLETE" ]]; then
  #                   echo "Exiting change-set status: $change_Status"
  #                   exit 0
  #               fi
  #               sleep 5
  #           done
  create_changes:
    description: Create stack infrasturcture changes 
    parameters:
      access_key_id: 
        type: string
        description: AWS access key Id
        default: $AWS_USER_ACCESS_KEY_ID
      secret_access_key: 
        type: string
        description: AWS secret access key
        default: $AWS_USER_SECRET_ACCESS_KEY
      region: 
        type: string
        description: AWS default region
        default: $AWS_DEFAULT_REGION
      stackname:
        description: Name of stack 
        type: string
        default: $CFN_STACKS
      s3bucket:
        description: Name of S3 bucket to store cloudformation artifacts 
        type: string
        default: $CFN_BUCKET
      changename:
        description: Name of stack change set
        type: string 
      version:
        description: Template version
        type: string 
      capabilities:
        description: IAM user 
        type: string
        default: $AWS_IAM   
      type:
        description: Type of change 
        type: string
        default: UPDATE 
    steps:
      # - attach_workspace:
      #     at: ~/.aws
      - run:
          name: Upload templates to S3 
          command: |
            
            aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID 

            aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY 

            cd .circleci/files/
            aws cloudformation package --template-file \
              stacks_v<<parameters.version>>.yaml \
              --s3-bucket <<parameters.s3bucket>> \
              --output-template-file stacks_v<<parameters.version>>-packaged.yaml
          environment:
            AWS_ACCESS_KEY_ID: <<parameters.access_key_id>>
            AWS_DEFAULT_REGION: <<parameters.region>>
            AWS_SECRET_ACCESS_KEY: <<parameters.secret_access_key>>
      - run: 
          name: Wait for local packaged file
          command: |
            # Wait for local file
            while [ ! -f ".circleci/files/stacks_v<<parameters.version>>-packaged.yaml" ] ; do
              echo "..."
            done        
      - run:
          name: Apply <<parameters.changename>> changes
          command: |
            
            aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID 

            aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY 

            change_set_ID=$(aws --output text --query "Id" cloudformation create-change-set \
              --stack-name <<parameters.stackname>> \
              --template-body file://.circleci/files/stacks_v<<parameters.version>>-packaged.yaml \
              --capabilities <<parameters.capabilities>> \
              --change-set-name <<parameters.changename>> \
              --change-set-type <<parameters.type>> )
            # echo $change_set_ID
          environment:
            AWS_ACCESS_KEY_ID: <<parameters.access_key_id>>
            AWS_DEFAULT_REGION: <<parameters.region>>
            AWS_SECRET_ACCESS_KEY: <<parameters.secret_access_key>>
      # - change_status:
      #     # user_role: <<parameters.user_role>>
      #     changename: <<parameters.changename>>
      - run:
          name: <<parameters.changename>> Status 
          command: |
            
            aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID 

            aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY 

            while [ 1 ]   # Endless loop.
            do
                change_Status=$(aws --output text --query "Status" cloudformation describe-change-set \
                    --change-set-name <<parameters.changename>> --stack-name $CFN_STACKS)
                echo "Change Status: $change_Status"
                if [[ $change_Status == "CREATE_COMPLETE" ]]; then
                    echo "Exiting change-set status: $change_Status"
                    exit 0
                fi
                sleep 5
            done
          environment:
            AWS_ACCESS_KEY_ID: <<parameters.access_key_id>>
            AWS_DEFAULT_REGION: <<parameters.region>>
            AWS_SECRET_ACCESS_KEY: <<parameters.secret_access_key>>
      - run:
          name: Setup <<parameters.changename>> infrastructure 
          command: |
            
            aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID 

            aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY 

            aws cloudformation execute-change-set --change-set-name <<parameters.changename>> --stack-name <<parameters.stackname>>
          environment:
            AWS_ACCESS_KEY_ID: <<parameters.access_key_id>>
            AWS_DEFAULT_REGION: <<parameters.region>>
            AWS_SECRET_ACCESS_KEY: <<parameters.secret_access_key>>
      # - stack_status:
      #     # user_role: <<parameters.user_role>>
      #     stackname: <<parameters.stackname>>
      - run:
          name: <<parameters.stackname>> Status 
          command: |
            
            aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID 

            aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY 

            while [ 1 ]   # Endless loop.
            do
                stack_Status=$(aws --output text --query "Stacks[0].StackStatus" cloudformation describe-stacks \
                    --stack-name <<parameters.stackname>>)
                echo "Stack Status: $stack_Status"
                if [[ $stack_Status == "CREATE_COMPLETE" || $stack_Status == "UPDATE_COMPLETE"  ]]; then
                    echo "Exiting stack status: $stack_Status"
                    exit 0
                elif [[ $stack_Status == "CREATE_FAILED" || $stack_Status == "ROLLBACK_IN_PROGRESS" || $stack_Status == "ROLLBACK_COMPLETE" || $stack_Status == "UPDATE_ROLLBACK_COMPLETE" || $stack_Status == "DELETE_IN_PROGRESS" ]]; then
                    echo "Exiting stack status: $stack_Status"
                    exit 1
                fi
                sleep 5
            done
          environment:
            AWS_ACCESS_KEY_ID: <<parameters.access_key_id>>
            AWS_DEFAULT_REGION: <<parameters.region>>
            AWS_SECRET_ACCESS_KEY: <<parameters.secret_access_key>>
  security_changes:
    description: Create IAM roles and Security groups 
    parameters:
      access_key_id: 
        type: string
        description: AWS access key Id
        default: $AWS_ADMIN_ACCESS_KEY_ID
      secret_access_key: 
        type: string
        description: AWS secret access key
        default: $AWS_ADMIN_SECRET_ACCESS_KEY
      region: 
        type: string
        description: AWS default region
        default: $AWS_DEFAULT_REGION
      stackname:
        description: Name of stack 
        type: string
        default: $CFN_STACKS
      changename:
        description: Name of stack change set
        type: string 
      type:
        description: Type of change 
        type: string
        default: UPDATE  
      version:
        description: Template version
        type: string 
    steps: 
      # configure aws cli for admin users 
      # - configure_aws:
      #     access_key_id: $AWS_ADMIN_ACCESS_KEY_ID
      #     secret_access_key: $AWS_ADMIN_SECRET_ACCESS_KEY
      #     profile_name: $ADMIN_USER_NAME        
      - create_changes:
          # user_role: $ADMIN_USER_NAME
          access_key_id: <<parameters.access_key_id>>
          secret_access_key: <<parameters.secret_access_key>>
          region: <<parameters.region>>
          changename: <<parameters.changename>>
          version: <<parameters.version>>
          type: <<parameters.type>>
    # when:
    #   condition:
    #     equal: [ $CIRCLE_USERNAME, $ADMIN_USER_NAME ]
# 
defaults: &defaults
  docker:
    - image: circleci/node:13.8.0
            
jobs:
  build-frontend:
    <<: *defaults
    steps:
      - checkout
      - check_master
      - restore_cache:
          keys: 
            - v1-frontend-build-{{ checksum "./frontend/package-lock.json" }}
            # fallback to using the latest cache 
            - v1-frontend-build-
      - run:
          name: Build front-end
          command: |
            cd ./frontend
            npm i
            npm run build
      - save_cache:
          paths: 
            - frontend/node_modules
          key: v1-frontend-build-{{ checksum "./frontend/package-lock.json" }}
      # - when:
      #     condition: on_fail
      #     steps:
      #       - revert-commit:
      #           commit_sha: $CIRCLE_SHA1  
      # - jira/notify

  build-backend:
    <<: *defaults
    steps:
      - checkout
      - check_master
      - restore_cache:
          keys:
            - v1-backend-build-{{ checksum "./backend/package-lock.json" }}
            # fallback to using the latest cache 
            - v1-backend-build-
      - run:
          name: Back-end build
          command: |
            cd ./backend
            npm i
            npm run build
      - save_cache:
          paths: 
            - backend/node_modules
          key: v1-backend-build-{{ checksum "./backend/package-lock.json" }}
      # - when:
      #     condition: on_fail
      #     steps:
      #       - revert-commit:
      #           commit_sha: $CIRCLE_SHA1  
      # - jira/notify

  test-frontend:
    <<: *defaults
    steps:
      - checkout
      - check_master
      # Restore from cache
      - restore_cache:
          keys: 
            - v1-frontend-build-{{ checksum "./frontend/package-lock.json" }}
            # fallback to using the latest cache 
            - v1-frontend-build-
      - run:
          name: Test front-end
          command: |
            cd ./frontend 
            npm i
            npm test 
      # - jira/notify              
      - slack/notify:
          event: fail
          template: basic_fail_1
      - slack/notify:
          event: pass
          template: basic_success_1
      # - run:
      #     name: Notify failed Tests
      #     command: curl --data fail_tests.log http://example.com/error_logs
      #     when: on_fail             
  test-backend:
    <<: *defaults
    steps:
      - checkout
      - check_master
      # Restore from cache
      - restore_cache:
          keys: 
            - v1-backend-build-{{ checksum "./backend/package-lock.json" }}
            # fallback to using the latest cache 
            - v1-backend-build-
      - run:
          name: Test front-end
          command: |
            cd ./backend 
            npm i
            npm test 
      # - jira/notify            
      - slack/notify:
          event: fail
          template: basic_fail_1
      - slack/notify:
          event: pass
          template: basic_success_1
      # - run:
      #     name: Notify failed Tests
      #     command: curl --data fail_tests.log http://example.com/error_logs
      #     when: on_fail             
  scan-frontend:
    <<: *defaults
    steps:
      - checkout
      - check_master
      # Restore from cache
      - restore_cache:
          keys: 
            - v1-frontend-build-{{ checksum "./frontend/package-lock.json" }}
            # fallback to using the latest cache 
            - v1-frontend-build-
      - run:
          name: Scan front-end
          command: |
            cd ./frontend 
            npm install 
            #npm audit --audit-level=critical
            npm audit fix --audit-level=critical --force
# Will be a good idea to commit the audit fix. This should be run by authorize  $USER_NAME.
      # - commit_to_github:
      #     commit_message: "NO_BUILD [skip ci] Pipeline frontend audit fix"
      # - jira/notify
      - slack/notify:
          event: fail
          template: basic_fail_1
  scan-backend:
    <<: *defaults
    steps:
      - checkout
      - check_master
      # Restore from cache
      - restore_cache:
          keys: 
            - v1-backend-build-{{ checksum "./backend/package-lock.json" }}
            # fallback to using the latest cache 
            - v1-backend-build-
      - run:
          name: Scan front-end
          command: |
            cd ./backend 
            npm install
            #npm audit --audit-level=critical 
            npm audit fix --audit-level=critical --force
# Will be a good idea to commit the audit fix. This should be run by authorize $USER_NAME. 
      # - commit_to_github:
      #     commit_message: "NO_BUILD [skip ci] backend audit fix"
      # - jira/notify
      - slack/notify:
          event: fail
          template: basic_fail_1
  scan-sonar:
    <<: *defaults
    steps:
      - checkout
      - check_master
      - scan:
          project_root: .
      # Restore from cache
      # - jira/notify
      - slack/notify:
          event: fail
          template: basic_fail_1
  deploy-infrastructure:
    docker:
      - image: cimg/python:3.9.13-node
    steps:
      - install_aws
      - checkout
      - check_master

      # security_changes : 
      # This is run by an IAM user with admin role
      # to setup priviledges required by other steps which are run by other IAM users
      # for simplicity the progres database is also setup by compliance change-set.
      # Ideally there should be another step after compliance change-set for database admin users
      - security_changes:
          access_key_id: $AWS_ADMIN_ACCESS_KEY_ID
          secret_access_key: $AWS_ADMIN_SECRET_ACCESS_KEY
          region: $AWS_DEFAULT_REGION
          stackname: $CFN_STACKS
          changename: compliance
          type: CREATE
          version: "1.0"
      # - database

      # configure aws cli for other users e.g devops team and web developers (use default settings)
      # - configure_aws
      - create_changes:
          access_key_id: $AWS_USER_ACCESS_KEY_ID
          secret_access_key: $AWS_USER_SECRET_ACCESS_KEY
          region: $AWS_DEFAULT_REGION
          stackname: $CFN_STACKS
          changename: deploy-backend
          # type: UPDATE # default setting
          version: "1.1"
      - create_changes:
          access_key_id: $AWS_USER_ACCESS_KEY_ID
          secret_access_key: $AWS_USER_SECRET_ACCESS_KEY
          region: $AWS_DEFAULT_REGION
          stackname: $CFN_STACKS
          changename: deploy-frontend
          version: "1.2"
      - security_changes:
          access_key_id: $AWS_ADMIN_ACCESS_KEY_ID
          secret_access_key: $AWS_ADMIN_SECRET_ACCESS_KEY
          region: $AWS_DEFAULT_REGION
          stackname: $CFN_STACKS
          changename: s3policy
          type: UPDATE
          version: "1.3"
#       - run:
#           name: Add back-end ip to ansible inventory
#           command: |
#             # Your code here
#             exit 1
#       - persist_to_workspace:
#           root: ~/
#           paths:
#             - project/.circleci/ansible/inventory.txt

# Here's where you will add some code to rollback on failure
# ----------------------------------------------------------
# create_changes command exits on failure notify concern individuals here.
# Cloudformation is set to automatically rollback to last successfull update.
# You can execute a rollback here with the commands below but
# it will be better to deal with cloudformation rollbacks at AWS end 
# to avoid an endless loop checking on AWS stack events.
      # - create_changes:
      #     stackname: $CFN_STACKS
      #     changename: rollback-deploy
      #     version: "1.0"  # rollback changes to security_changes and admin user can delete
      - slack/notify:
          event: fail
          template: basic_fail_1
#   configure-infrastructure:
#     docker:
#       # Docker image here that supports Ansible
#     steps:
#       # Checkout code from git
        # - checkout
#       # Add ssh keys with fingerprint
      # - add_ssh_keys:
      #     fingerprints:
      #       - "<copy-paste-fingerprint-here>"
#       # attach workspace
      # - attach_workspace:
      #     at: ~/
#       - run:
#           name: Install dependencies
#           command: |
#             # Your code here
#             exit 1
#       - run:
#           name: Configure server
#           command: |
#             # Your code here
#             exit 1
#       # Here's where you will add some code to rollback on failure      

#   run-migrations:
#     docker:
#       # Docker image here that supports NodeJS
#     steps:
#       # Checkout code from git
#       - run:
#           name: Run migrations
#           command: |
#             # Your code here
#             exit 1
#       - run:
#           name: Send migration results to memstash
#           command: |
#             # Your code here
#             exit 1
#      # Here's where you will add some code to rollback on failure      

#   deploy-frontend:
#     docker:
#       # Docker image here that supports AWS CLI
#     steps:
#       # Checkout code from git
#       - run:
#           name: Install dependencies
#           command: |
#             # your code here
#       - run:
#           name: Get backend url
#           command: |
#             # your code here
#             export API_URL="http://${BACKEND_IP}:3030"
#             echo "${API_URL}"
#       - run:
#           name: Deploy frontend objects
#           command: |
#             # your code here
#       # Here's where you will add some code to rollback on failure      
                    
#   deploy-backend:
#     docker:
#       # Docker image here that supports Ansible
#     steps:
#       # Checkout code from git
#       # Add ssh keys with fingerprint
#       # attach workspace
#       - run:
#           name: Install dependencies
#           command: |
#             # your code here
#       - run:
#           name: Deploy backend
#           command: |
#             # your code here
#       # Here's where you will add some code to rollback on failure  

#   smoke-test:
#     docker:
#       # Lightweight Docker image 
#     steps:
#       # Checkout code from git
#       - run:
#           name: Install dependencies
#           command: |
#             # your code here
#       - run:
#           name: Get backend url
#           command: |
#             # your code here
#       - run:
#           name: Backend smoke test.
#           command: |
#             # your code here
#       - run:
#           name: Frontend smoke test.
#           command: |
#             # your code here
#       # Here's where you will add some code to rollback on failure  

#   cloudfront-update:
#     docker:
#       # Docker image here that supports AWS CLI
#     steps:
#       # Checkout code from git
#       - run:
#           name: Install dependencies
#           command: |
#             # your code here
#       - run:
#           name: Update cloudfront distribution
#           command: |
#             # your code here
#       # Here's where you will add some code to rollback on failure  

# cleanup:
#     docker:
#       # Docker image here
#     steps:
#       # Checkout code from git
#       - run:
#           name: Get old stack workflow id
#           command: |
#             # your code here
#             export OldWorkflowID="the id here"
#             export STACKS=[] #put the list of stacks here
#       - run:
#           name: Remove old stacks and files
#           command: |
#             if [[ "${STACKS[@]}" =~ "${OldWorkflowID}" ]]
#             then
#               # your code here
#             fi
workflows:
  default:
    jobs:
      - build-frontend:
          pre-steps: # Check commit message if NO_BUILD
            - cancel-workflow      
      - build-backend:
          pre-steps: # Check commit message if NO_BUILD
            - cancel-workflow
      - test-frontend:
          post-steps:
            - jira/notify:
                environment_type: testing
                job_type: build
          requires: 
            - build-frontend
          # filters:
          #   branches:
          #     only: master
      - test-backend:
          post-steps:
            - jira/notify:
                environment_type: testing
                job_type: build
          requires: 
            - build-backend
          # filters:
          #   branches:
          #     only: master
      - scan-backend:
          post-steps:
            - jira/notify:
                environment_type: testing
                job_type: build
          requires: 
            - build-backend
      - scan-frontend:
          post-steps:
            - jira/notify:
                environment_type: testing
                job_type: build
          requires: 
            - build-frontend
      - scan-sonar:
          post-steps:
            - when:
                condition: on_fail
                steps:
                - jira/notify:
                    environment_type: testing
                    job_type: build
          requires: 
            - build-frontend
            - build-backend
      - deploy-infrastructure:
          requires: 
            - test-frontend
            - test-backend
            - scan-frontend
            - scan-backend
          context:
            - org-global
            - aws-context
      # - configure-infrastructure:
      #     requires: [deploy-infrastructure]
      # - run-migrations:
      #     requires: [configure-infrastructure]
      # - deploy-frontend:
      #     requires: [run-migrations]
      # - deploy-backend:
      #     requires: [run-migrations]
      # - smoke-test:
      #     requires: [deploy-backend, deploy-frontend]
      # - cloudfront-update:
      #     requires: [smoke-test]
      # - cleanup:
      #     requires: [cloudfront-update]
  nightly:
    jobs:
      - test-frontend
      - test-backend
    triggers:
      - schedule:
          cron: "0 0 * * *"
          filters:
            branches:
              only:
                - master
  # integration_tests:
  #   when: << pipeline.parameters.run_integration_tests >>
  #   jobs:
  #     - build-frontend
  #     - build-backend
  #     - deploy-infrastructure:
  #         requires: 
  #           - build-frontend
  #           - build-backend
  #         context:
  #           - org-global
  #           - aws-context
  #     - configure-infrastructure:
  #         requires: 
  #           - deploy-infrastructure
  #     - run-migrations:
  #         requires: 
  #           - configure-infrastructure
  #     - deploy-frontend:
  #         requires: 
  #           - run-migrations
  #     - deploy-backend:
  #         requires: 
  #           - run-migrations
  #     - cloudfront-update:
  #         requires: 
  #         - run-migrations
  #     - cleanup:
  #         requires: 
  #           - cloudfront-update